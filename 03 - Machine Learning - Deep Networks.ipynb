{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Networks\n",
    "\n",
    "The first algorithm that we will use is the XGBoost with its random forest classifier. This example uses a random forest version of the XGBoost classifier. This algorithm will be used for each generated feature, namelly:\n",
    "\n",
    "- Periodograms\n",
    "- Bayes Similarity\n",
    "- Hidden Markov Models\n",
    "\n",
    "All approaches will pass trough the common machine learning pipeline, where we must:\n",
    "\n",
    "- Normalize the data (if necessary)\n",
    "- Divide the data between trainning and testing\n",
    "- Search the hyper parameters\n",
    "- Cross validate the models\n",
    "- Analyse the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periodograms\n",
    "\n",
    "The application using the periodograms is actually pretty simple, now that the data is prepared and all of those preprocessing from last pipeline step is already done. The algorithm became straigh forward. First it is necessary to read the features generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'labels'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "file_name = './features/freq_data/freq_data.pkl' \n",
    "with open(file_name, 'rb') as file:\n",
    "    freq_data = pickle.load(file)\n",
    "freq_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate features\n",
    "\n",
    "After reading the data, it is necessary to create the classical regression structure model in the format $Y = f\\left(\\Theta, X\\right)$, normalize the feature data and encode any possible label data into numerical classes. This is just the preparation for the machine leaning algorithm to guarantee that the provided info is properlly designed for any machine learning classical form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Create the label encoder\n",
    "le_freq = preprocessing.LabelEncoder()\n",
    "le_freq.fit(freq_data['labels'])\n",
    "\n",
    "# Define the regression model\n",
    "regressors = preprocessing.normalize(freq_data['features']['spec'])\n",
    "outputs = le_freq.transform(freq_data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12758"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressors.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also it is interesting to reduce the features dimension to build a simpler model. It is not necessary to create a classifier with such amount (12758 features...) of features. There are several techniques that can be used to reduce the features dimensions. The Principal Component Analisys, is very effective when dealing with high dimensional data. Here the `PCA` algorithm from the `sklearn` library is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create the PCA decomposer\n",
    "pca_dec = PCA(n_components=69, svd_solver='arpack')\n",
    "\n",
    "# Train the PCA object\n",
    "pca_dec.fit(regressors)\n",
    "\n",
    "# Transform the data using\n",
    "# the PCA model\n",
    "pca_regressor = pca_dec.transform(regressors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test data split\n",
    "\n",
    "Next it is necessary to segregate the data into a set for validation and one for trainning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "    pca_regressor, outputs, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "After running the hyper parameter search we can create a model with the best defined hyper parameters, or setup parameters, and consolidate the model in to the best version for further performance analysis. The model is saved on a particular variable, such as `freq_clf` to be further used in some vote chain model, if further necessary. \n",
    "\n",
    "> *One interesting result from the above result, is that the best compromise result happens at the $n_x = 5$ not on $n_x=4$ as it seems. Even though for the $n_x=4$ the algorithm is able to get all the exo planets, the compromise on having a confidence of only 66% for the eclipsing binaries classification (classifier close to a coin flipper to classify eclipsing binaries), doesn't allow us to select $n_x=4$. Therefore the best trade-off on both classes happens at $n_x=5$.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46 samples, validate on 31 samples\n",
      "Epoch 1/200\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.4130 - val_loss: 0.6900 - val_accuracy: 0.5806\n",
      "Epoch 2/200\n",
      "46/46 [==============================] - 0s 196us/step - loss: 0.6898 - accuracy: 0.7174 - val_loss: 0.6942 - val_accuracy: 0.4839\n",
      "Epoch 3/200\n",
      "46/46 [==============================] - 0s 182us/step - loss: 0.6858 - accuracy: 0.7391 - val_loss: 0.6980 - val_accuracy: 0.4516\n",
      "Epoch 4/200\n",
      "46/46 [==============================] - 0s 239us/step - loss: 0.6824 - accuracy: 0.7391 - val_loss: 0.7014 - val_accuracy: 0.3871\n",
      "Epoch 5/200\n",
      "46/46 [==============================] - 0s 245us/step - loss: 0.6794 - accuracy: 0.7609 - val_loss: 0.7047 - val_accuracy: 0.3548\n",
      "Epoch 6/200\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.6765 - accuracy: 0.7609 - val_loss: 0.7076 - val_accuracy: 0.2903\n",
      "Epoch 7/200\n",
      "46/46 [==============================] - 0s 299us/step - loss: 0.6741 - accuracy: 0.7609 - val_loss: 0.7103 - val_accuracy: 0.2581\n",
      "Epoch 8/200\n",
      "46/46 [==============================] - 0s 336us/step - loss: 0.6716 - accuracy: 0.7826 - val_loss: 0.7131 - val_accuracy: 0.2581\n",
      "Epoch 9/200\n",
      "46/46 [==============================] - 0s 192us/step - loss: 0.6692 - accuracy: 0.7826 - val_loss: 0.7160 - val_accuracy: 0.2581\n",
      "Epoch 10/200\n",
      "46/46 [==============================] - 0s 268us/step - loss: 0.6668 - accuracy: 0.7826 - val_loss: 0.7190 - val_accuracy: 0.2258\n",
      "Epoch 11/200\n",
      "46/46 [==============================] - 0s 306us/step - loss: 0.6644 - accuracy: 0.7826 - val_loss: 0.7218 - val_accuracy: 0.2258\n",
      "Epoch 12/200\n",
      "46/46 [==============================] - 0s 336us/step - loss: 0.6621 - accuracy: 0.8043 - val_loss: 0.7249 - val_accuracy: 0.1935\n",
      "Epoch 13/200\n",
      "46/46 [==============================] - 0s 283us/step - loss: 0.6598 - accuracy: 0.8043 - val_loss: 0.7277 - val_accuracy: 0.1613\n",
      "Epoch 14/200\n",
      "46/46 [==============================] - 0s 288us/step - loss: 0.6575 - accuracy: 0.8261 - val_loss: 0.7306 - val_accuracy: 0.1613\n",
      "Epoch 15/200\n",
      "46/46 [==============================] - 0s 325us/step - loss: 0.6552 - accuracy: 0.8261 - val_loss: 0.7334 - val_accuracy: 0.0968\n",
      "Epoch 16/200\n",
      "46/46 [==============================] - 0s 283us/step - loss: 0.6531 - accuracy: 0.8261 - val_loss: 0.7362 - val_accuracy: 0.0323\n",
      "Epoch 17/200\n",
      "46/46 [==============================] - 0s 327us/step - loss: 0.6508 - accuracy: 0.8261 - val_loss: 0.7394 - val_accuracy: 0.0323\n",
      "Epoch 18/200\n",
      "46/46 [==============================] - 0s 328us/step - loss: 0.6486 - accuracy: 0.8261 - val_loss: 0.7423 - val_accuracy: 0.0323\n",
      "Epoch 19/200\n",
      "46/46 [==============================] - 0s 313us/step - loss: 0.6465 - accuracy: 0.8261 - val_loss: 0.7451 - val_accuracy: 0.0323\n",
      "Epoch 20/200\n",
      "46/46 [==============================] - 0s 317us/step - loss: 0.6442 - accuracy: 0.8261 - val_loss: 0.7480 - val_accuracy: 0.0323\n",
      "Epoch 21/200\n",
      "46/46 [==============================] - 0s 236us/step - loss: 0.6421 - accuracy: 0.8261 - val_loss: 0.7508 - val_accuracy: 0.0323\n",
      "Epoch 22/200\n",
      "46/46 [==============================] - 0s 189us/step - loss: 0.6400 - accuracy: 0.8261 - val_loss: 0.7537 - val_accuracy: 0.0323\n",
      "Epoch 23/200\n",
      "46/46 [==============================] - 0s 201us/step - loss: 0.6379 - accuracy: 0.8261 - val_loss: 0.7565 - val_accuracy: 0.0323\n",
      "Epoch 24/200\n",
      "46/46 [==============================] - 0s 186us/step - loss: 0.6358 - accuracy: 0.8261 - val_loss: 0.7591 - val_accuracy: 0.0323\n",
      "Epoch 25/200\n",
      "46/46 [==============================] - 0s 186us/step - loss: 0.6337 - accuracy: 0.8261 - val_loss: 0.7620 - val_accuracy: 0.0323\n",
      "Epoch 26/200\n",
      "46/46 [==============================] - 0s 229us/step - loss: 0.6316 - accuracy: 0.8261 - val_loss: 0.7647 - val_accuracy: 0.0323\n",
      "Epoch 27/200\n",
      "46/46 [==============================] - 0s 180us/step - loss: 0.6296 - accuracy: 0.8261 - val_loss: 0.7673 - val_accuracy: 0.0323\n",
      "Epoch 28/200\n",
      "46/46 [==============================] - 0s 188us/step - loss: 0.6275 - accuracy: 0.8261 - val_loss: 0.7703 - val_accuracy: 0.0323\n",
      "Epoch 29/200\n",
      "46/46 [==============================] - 0s 190us/step - loss: 0.6253 - accuracy: 0.8261 - val_loss: 0.7733 - val_accuracy: 0.0323\n",
      "Epoch 30/200\n",
      "46/46 [==============================] - 0s 196us/step - loss: 0.6231 - accuracy: 0.8261 - val_loss: 0.7762 - val_accuracy: 0.0323\n",
      "Epoch 31/200\n",
      "46/46 [==============================] - 0s 173us/step - loss: 0.6211 - accuracy: 0.8261 - val_loss: 0.7789 - val_accuracy: 0.0323\n",
      "Epoch 32/200\n",
      "46/46 [==============================] - 0s 236us/step - loss: 0.6190 - accuracy: 0.8261 - val_loss: 0.7816 - val_accuracy: 0.0323\n",
      "Epoch 33/200\n",
      "46/46 [==============================] - 0s 244us/step - loss: 0.6168 - accuracy: 0.8261 - val_loss: 0.7850 - val_accuracy: 0.0323\n",
      "Epoch 34/200\n",
      "46/46 [==============================] - 0s 331us/step - loss: 0.6144 - accuracy: 0.8261 - val_loss: 0.7880 - val_accuracy: 0.0323\n",
      "Epoch 35/200\n",
      "46/46 [==============================] - 0s 314us/step - loss: 0.6122 - accuracy: 0.8261 - val_loss: 0.7910 - val_accuracy: 0.0323\n",
      "Epoch 36/200\n",
      "46/46 [==============================] - 0s 293us/step - loss: 0.6099 - accuracy: 0.8261 - val_loss: 0.7943 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "46/46 [==============================] - 0s 255us/step - loss: 0.6075 - accuracy: 0.8261 - val_loss: 0.7975 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "46/46 [==============================] - 0s 277us/step - loss: 0.6051 - accuracy: 0.8261 - val_loss: 0.8009 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "46/46 [==============================] - 0s 200us/step - loss: 0.6027 - accuracy: 0.8261 - val_loss: 0.8044 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "46/46 [==============================] - 0s 300us/step - loss: 0.5998 - accuracy: 0.8261 - val_loss: 0.8083 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "46/46 [==============================] - 0s 341us/step - loss: 0.5970 - accuracy: 0.8261 - val_loss: 0.8121 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "46/46 [==============================] - 0s 380us/step - loss: 0.5943 - accuracy: 0.8261 - val_loss: 0.8159 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "46/46 [==============================] - 0s 204us/step - loss: 0.5916 - accuracy: 0.8261 - val_loss: 0.8197 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "46/46 [==============================] - 0s 301us/step - loss: 0.5889 - accuracy: 0.8261 - val_loss: 0.8234 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "46/46 [==============================] - 0s 207us/step - loss: 0.5862 - accuracy: 0.8261 - val_loss: 0.8273 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "46/46 [==============================] - 0s 260us/step - loss: 0.5835 - accuracy: 0.8261 - val_loss: 0.8312 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "46/46 [==============================] - 0s 239us/step - loss: 0.5809 - accuracy: 0.8261 - val_loss: 0.8348 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "46/46 [==============================] - 0s 204us/step - loss: 0.5784 - accuracy: 0.8261 - val_loss: 0.8384 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "46/46 [==============================] - 0s 271us/step - loss: 0.5758 - accuracy: 0.8261 - val_loss: 0.8421 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "46/46 [==============================] - 0s 274us/step - loss: 0.5731 - accuracy: 0.8261 - val_loss: 0.8463 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "46/46 [==============================] - 0s 222us/step - loss: 0.5705 - accuracy: 0.8261 - val_loss: 0.8501 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "46/46 [==============================] - 0s 292us/step - loss: 0.5679 - accuracy: 0.8261 - val_loss: 0.8544 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "46/46 [==============================] - 0s 217us/step - loss: 0.5653 - accuracy: 0.8261 - val_loss: 0.8582 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "46/46 [==============================] - 0s 320us/step - loss: 0.5627 - accuracy: 0.8261 - val_loss: 0.8625 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "46/46 [==============================] - 0s 242us/step - loss: 0.5601 - accuracy: 0.8261 - val_loss: 0.8663 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.5577 - accuracy: 0.8261 - val_loss: 0.8702 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 288us/step - loss: 0.5551 - accuracy: 0.8261 - val_loss: 0.8746 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "46/46 [==============================] - 0s 320us/step - loss: 0.5525 - accuracy: 0.8261 - val_loss: 0.8786 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "46/46 [==============================] - 0s 455us/step - loss: 0.5500 - accuracy: 0.8261 - val_loss: 0.8828 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "46/46 [==============================] - 0s 245us/step - loss: 0.5476 - accuracy: 0.8261 - val_loss: 0.8872 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "46/46 [==============================] - 0s 206us/step - loss: 0.5450 - accuracy: 0.8261 - val_loss: 0.8908 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "46/46 [==============================] - 0s 179us/step - loss: 0.5427 - accuracy: 0.8261 - val_loss: 0.8946 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "46/46 [==============================] - 0s 214us/step - loss: 0.5404 - accuracy: 0.8261 - val_loss: 0.8986 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "46/46 [==============================] - 0s 225us/step - loss: 0.5379 - accuracy: 0.8261 - val_loss: 0.9025 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "46/46 [==============================] - 0s 180us/step - loss: 0.5355 - accuracy: 0.8261 - val_loss: 0.9066 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "46/46 [==============================] - 0s 231us/step - loss: 0.5331 - accuracy: 0.8261 - val_loss: 0.9102 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "46/46 [==============================] - 0s 229us/step - loss: 0.5308 - accuracy: 0.8261 - val_loss: 0.9143 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "46/46 [==============================] - 0s 180us/step - loss: 0.5282 - accuracy: 0.8261 - val_loss: 0.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "46/46 [==============================] - 0s 185us/step - loss: 0.5259 - accuracy: 0.8261 - val_loss: 0.9230 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "46/46 [==============================] - 0s 239us/step - loss: 0.5234 - accuracy: 0.8261 - val_loss: 0.9269 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "46/46 [==============================] - 0s 218us/step - loss: 0.5210 - accuracy: 0.8261 - val_loss: 0.9312 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "46/46 [==============================] - 0s 227us/step - loss: 0.5186 - accuracy: 0.8261 - val_loss: 0.9358 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "46/46 [==============================] - 0s 219us/step - loss: 0.5162 - accuracy: 0.8261 - val_loss: 0.9399 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "46/46 [==============================] - 0s 185us/step - loss: 0.5138 - accuracy: 0.8261 - val_loss: 0.9447 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "46/46 [==============================] - 0s 170us/step - loss: 0.5116 - accuracy: 0.8261 - val_loss: 0.9489 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "46/46 [==============================] - 0s 295us/step - loss: 0.5093 - accuracy: 0.8261 - val_loss: 0.9525 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "46/46 [==============================] - 0s 213us/step - loss: 0.5070 - accuracy: 0.8261 - val_loss: 0.9570 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "46/46 [==============================] - 0s 251us/step - loss: 0.5047 - accuracy: 0.8261 - val_loss: 0.9617 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "46/46 [==============================] - 0s 227us/step - loss: 0.5023 - accuracy: 0.8261 - val_loss: 0.9661 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "46/46 [==============================] - 0s 213us/step - loss: 0.5002 - accuracy: 0.8261 - val_loss: 0.9701 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "46/46 [==============================] - 0s 231us/step - loss: 0.4979 - accuracy: 0.8261 - val_loss: 0.9751 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "46/46 [==============================] - 0s 217us/step - loss: 0.4957 - accuracy: 0.8261 - val_loss: 0.9788 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "46/46 [==============================] - 0s 256us/step - loss: 0.4935 - accuracy: 0.8261 - val_loss: 0.9837 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "46/46 [==============================] - 0s 204us/step - loss: 0.4913 - accuracy: 0.8261 - val_loss: 0.9886 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "46/46 [==============================] - 0s 172us/step - loss: 0.4891 - accuracy: 0.8261 - val_loss: 0.9925 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "46/46 [==============================] - 0s 221us/step - loss: 0.4869 - accuracy: 0.8261 - val_loss: 0.9969 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "46/46 [==============================] - 0s 196us/step - loss: 0.4847 - accuracy: 0.8261 - val_loss: 1.0019 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "46/46 [==============================] - 0s 196us/step - loss: 0.4825 - accuracy: 0.8261 - val_loss: 1.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "46/46 [==============================] - 0s 259us/step - loss: 0.4803 - accuracy: 0.8261 - val_loss: 1.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "46/46 [==============================] - 0s 231us/step - loss: 0.4781 - accuracy: 0.8261 - val_loss: 1.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "46/46 [==============================] - 0s 192us/step - loss: 0.4760 - accuracy: 0.8261 - val_loss: 1.0208 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "46/46 [==============================] - 0s 221us/step - loss: 0.4739 - accuracy: 0.8261 - val_loss: 1.0256 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "46/46 [==============================] - 0s 241us/step - loss: 0.4717 - accuracy: 0.8261 - val_loss: 1.0303 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "46/46 [==============================] - 0s 279us/step - loss: 0.4697 - accuracy: 0.8261 - val_loss: 1.0352 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "46/46 [==============================] - 0s 219us/step - loss: 0.4677 - accuracy: 0.8261 - val_loss: 1.0399 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "46/46 [==============================] - 0s 197us/step - loss: 0.4655 - accuracy: 0.8261 - val_loss: 1.0450 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "46/46 [==============================] - 0s 206us/step - loss: 0.4634 - accuracy: 0.8261 - val_loss: 1.0502 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "46/46 [==============================] - 0s 183us/step - loss: 0.4614 - accuracy: 0.8261 - val_loss: 1.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "46/46 [==============================] - 0s 216us/step - loss: 0.4593 - accuracy: 0.8261 - val_loss: 1.0596 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "46/46 [==============================] - 0s 194us/step - loss: 0.4574 - accuracy: 0.8261 - val_loss: 1.0639 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "46/46 [==============================] - 0s 217us/step - loss: 0.4554 - accuracy: 0.8261 - val_loss: 1.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "46/46 [==============================] - 0s 171us/step - loss: 0.4534 - accuracy: 0.8261 - val_loss: 1.0741 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "46/46 [==============================] - 0s 169us/step - loss: 0.4514 - accuracy: 0.8261 - val_loss: 1.0794 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "46/46 [==============================] - 0s 197us/step - loss: 0.4496 - accuracy: 0.8478 - val_loss: 1.0848 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "46/46 [==============================] - 0s 174us/step - loss: 0.4475 - accuracy: 0.8478 - val_loss: 1.0891 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "46/46 [==============================] - 0s 179us/step - loss: 0.4456 - accuracy: 0.8478 - val_loss: 1.0937 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "46/46 [==============================] - 0s 207us/step - loss: 0.4437 - accuracy: 0.8478 - val_loss: 1.0982 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "46/46 [==============================] - 0s 179us/step - loss: 0.4420 - accuracy: 0.8478 - val_loss: 1.1038 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "46/46 [==============================] - 0s 217us/step - loss: 0.4400 - accuracy: 0.8478 - val_loss: 1.1085 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "46/46 [==============================] - 0s 188us/step - loss: 0.4382 - accuracy: 0.8478 - val_loss: 1.1133 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "46/46 [==============================] - 0s 239us/step - loss: 0.4364 - accuracy: 0.8478 - val_loss: 1.1183 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 245us/step - loss: 0.4347 - accuracy: 0.8478 - val_loss: 1.1237 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "46/46 [==============================] - 0s 272us/step - loss: 0.4328 - accuracy: 0.8478 - val_loss: 1.1286 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "46/46 [==============================] - 0s 256us/step - loss: 0.4308 - accuracy: 0.8478 - val_loss: 1.1337 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "46/46 [==============================] - 0s 231us/step - loss: 0.4292 - accuracy: 0.8478 - val_loss: 1.1383 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "46/46 [==============================] - 0s 215us/step - loss: 0.4273 - accuracy: 0.8478 - val_loss: 1.1441 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.4257 - accuracy: 0.8478 - val_loss: 1.1491 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "46/46 [==============================] - 0s 251us/step - loss: 0.4239 - accuracy: 0.8478 - val_loss: 1.1537 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "46/46 [==============================] - 0s 233us/step - loss: 0.4222 - accuracy: 0.8478 - val_loss: 1.1588 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "46/46 [==============================] - 0s 239us/step - loss: 0.4205 - accuracy: 0.8478 - val_loss: 1.1633 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "46/46 [==============================] - 0s 184us/step - loss: 0.4189 - accuracy: 0.8478 - val_loss: 1.1690 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "46/46 [==============================] - 0s 253us/step - loss: 0.4172 - accuracy: 0.8478 - val_loss: 1.1736 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "46/46 [==============================] - 0s 211us/step - loss: 0.4154 - accuracy: 0.8478 - val_loss: 1.1785 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "46/46 [==============================] - 0s 224us/step - loss: 0.4138 - accuracy: 0.8478 - val_loss: 1.1837 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "46/46 [==============================] - 0s 191us/step - loss: 0.4123 - accuracy: 0.8478 - val_loss: 1.1888 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "46/46 [==============================] - 0s 228us/step - loss: 0.4106 - accuracy: 0.8478 - val_loss: 1.1937 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "46/46 [==============================] - 0s 251us/step - loss: 0.4090 - accuracy: 0.8478 - val_loss: 1.1991 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "46/46 [==============================] - 0s 204us/step - loss: 0.4074 - accuracy: 0.8478 - val_loss: 1.2038 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "46/46 [==============================] - 0s 203us/step - loss: 0.4059 - accuracy: 0.8478 - val_loss: 1.2096 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "46/46 [==============================] - 0s 181us/step - loss: 0.4046 - accuracy: 0.8478 - val_loss: 1.2130 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "46/46 [==============================] - 0s 181us/step - loss: 0.4030 - accuracy: 0.8478 - val_loss: 1.2174 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "46/46 [==============================] - 0s 189us/step - loss: 0.4015 - accuracy: 0.8478 - val_loss: 1.2219 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "46/46 [==============================] - 0s 200us/step - loss: 0.4001 - accuracy: 0.8478 - val_loss: 1.2261 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "46/46 [==============================] - 0s 199us/step - loss: 0.3988 - accuracy: 0.8478 - val_loss: 1.2292 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "46/46 [==============================] - 0s 216us/step - loss: 0.3973 - accuracy: 0.8478 - val_loss: 1.2338 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "46/46 [==============================] - 0s 240us/step - loss: 0.3959 - accuracy: 0.8478 - val_loss: 1.2386 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "46/46 [==============================] - 0s 288us/step - loss: 0.3948 - accuracy: 0.8478 - val_loss: 1.2417 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "46/46 [==============================] - 0s 237us/step - loss: 0.3933 - accuracy: 0.8478 - val_loss: 1.2467 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "46/46 [==============================] - 0s 207us/step - loss: 0.3919 - accuracy: 0.8478 - val_loss: 1.2513 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "46/46 [==============================] - 0s 222us/step - loss: 0.3905 - accuracy: 0.8478 - val_loss: 1.2558 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "46/46 [==============================] - 0s 226us/step - loss: 0.3892 - accuracy: 0.8478 - val_loss: 1.2602 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "46/46 [==============================] - 0s 213us/step - loss: 0.3877 - accuracy: 0.8478 - val_loss: 1.2657 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "46/46 [==============================] - 0s 212us/step - loss: 0.3863 - accuracy: 0.8478 - val_loss: 1.2703 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "46/46 [==============================] - 0s 195us/step - loss: 0.3850 - accuracy: 0.8478 - val_loss: 1.2754 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "46/46 [==============================] - 0s 224us/step - loss: 0.3840 - accuracy: 0.8478 - val_loss: 1.2803 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "46/46 [==============================] - 0s 254us/step - loss: 0.3824 - accuracy: 0.8478 - val_loss: 1.2846 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "46/46 [==============================] - 0s 268us/step - loss: 0.3812 - accuracy: 0.8696 - val_loss: 1.2887 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "46/46 [==============================] - 0s 211us/step - loss: 0.3799 - accuracy: 0.8696 - val_loss: 1.2932 - val_accuracy: 0.0323\n",
      "Epoch 149/200\n",
      "46/46 [==============================] - 0s 236us/step - loss: 0.3786 - accuracy: 0.8696 - val_loss: 1.2971 - val_accuracy: 0.0323\n",
      "Epoch 150/200\n",
      "46/46 [==============================] - 0s 329us/step - loss: 0.3774 - accuracy: 0.8696 - val_loss: 1.3023 - val_accuracy: 0.0323\n",
      "Epoch 151/200\n",
      "46/46 [==============================] - 0s 265us/step - loss: 0.3759 - accuracy: 0.8696 - val_loss: 1.3079 - val_accuracy: 0.0323\n",
      "Epoch 152/200\n",
      "46/46 [==============================] - 0s 232us/step - loss: 0.3750 - accuracy: 0.8696 - val_loss: 1.3107 - val_accuracy: 0.0323\n",
      "Epoch 153/200\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.3738 - accuracy: 0.8696 - val_loss: 1.3154 - val_accuracy: 0.0323\n",
      "Epoch 154/200\n",
      "46/46 [==============================] - 0s 279us/step - loss: 0.3726 - accuracy: 0.8696 - val_loss: 1.3193 - val_accuracy: 0.0323\n",
      "Epoch 155/200\n",
      "46/46 [==============================] - 0s 284us/step - loss: 0.3714 - accuracy: 0.8696 - val_loss: 1.3237 - val_accuracy: 0.0323\n",
      "Epoch 156/200\n",
      "46/46 [==============================] - 0s 240us/step - loss: 0.3701 - accuracy: 0.8696 - val_loss: 1.3281 - val_accuracy: 0.0323\n",
      "Epoch 157/200\n",
      "46/46 [==============================] - 0s 254us/step - loss: 0.3689 - accuracy: 0.8696 - val_loss: 1.3323 - val_accuracy: 0.0323\n",
      "Epoch 158/200\n",
      "46/46 [==============================] - 0s 197us/step - loss: 0.3677 - accuracy: 0.8913 - val_loss: 1.3373 - val_accuracy: 0.0323\n",
      "Epoch 159/200\n",
      "46/46 [==============================] - 0s 196us/step - loss: 0.3666 - accuracy: 0.8913 - val_loss: 1.3414 - val_accuracy: 0.0323\n",
      "Epoch 160/200\n",
      "46/46 [==============================] - 0s 253us/step - loss: 0.3655 - accuracy: 0.8913 - val_loss: 1.3447 - val_accuracy: 0.0323\n",
      "Epoch 161/200\n",
      "46/46 [==============================] - 0s 232us/step - loss: 0.3643 - accuracy: 0.8913 - val_loss: 1.3489 - val_accuracy: 0.0323\n",
      "Epoch 162/200\n",
      "46/46 [==============================] - 0s 202us/step - loss: 0.3633 - accuracy: 0.8913 - val_loss: 1.3510 - val_accuracy: 0.0323\n",
      "Epoch 163/200\n",
      "46/46 [==============================] - 0s 220us/step - loss: 0.3621 - accuracy: 0.8913 - val_loss: 1.3562 - val_accuracy: 0.0323\n",
      "Epoch 164/200\n",
      "46/46 [==============================] - 0s 237us/step - loss: 0.3610 - accuracy: 0.8913 - val_loss: 1.3609 - val_accuracy: 0.0323\n",
      "Epoch 165/200\n",
      "46/46 [==============================] - 0s 246us/step - loss: 0.3600 - accuracy: 0.8913 - val_loss: 1.3653 - val_accuracy: 0.0323\n",
      "Epoch 166/200\n",
      "46/46 [==============================] - 0s 277us/step - loss: 0.3591 - accuracy: 0.8913 - val_loss: 1.3693 - val_accuracy: 0.0323\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 255us/step - loss: 0.3579 - accuracy: 0.8913 - val_loss: 1.3737 - val_accuracy: 0.0323\n",
      "Epoch 168/200\n",
      "46/46 [==============================] - 0s 206us/step - loss: 0.3568 - accuracy: 0.8913 - val_loss: 1.3766 - val_accuracy: 0.0323\n",
      "Epoch 169/200\n",
      "46/46 [==============================] - 0s 270us/step - loss: 0.3557 - accuracy: 0.8913 - val_loss: 1.3806 - val_accuracy: 0.0323\n",
      "Epoch 170/200\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3935 - accuracy: 0.87 - 0s 234us/step - loss: 0.3546 - accuracy: 0.8913 - val_loss: 1.3848 - val_accuracy: 0.0323\n",
      "Epoch 171/200\n",
      "46/46 [==============================] - 0s 200us/step - loss: 0.3537 - accuracy: 0.8913 - val_loss: 1.3882 - val_accuracy: 0.0323\n",
      "Epoch 172/200\n",
      "46/46 [==============================] - 0s 204us/step - loss: 0.3526 - accuracy: 0.8913 - val_loss: 1.3912 - val_accuracy: 0.0323\n",
      "Epoch 173/200\n",
      "46/46 [==============================] - 0s 231us/step - loss: 0.3518 - accuracy: 0.8913 - val_loss: 1.3952 - val_accuracy: 0.0323\n",
      "Epoch 174/200\n",
      "46/46 [==============================] - 0s 265us/step - loss: 0.3506 - accuracy: 0.8913 - val_loss: 1.3989 - val_accuracy: 0.0323\n",
      "Epoch 175/200\n",
      "46/46 [==============================] - 0s 225us/step - loss: 0.3496 - accuracy: 0.8913 - val_loss: 1.4024 - val_accuracy: 0.0323\n",
      "Epoch 176/200\n",
      "46/46 [==============================] - 0s 280us/step - loss: 0.3486 - accuracy: 0.8913 - val_loss: 1.4071 - val_accuracy: 0.0323\n",
      "Epoch 177/200\n",
      "46/46 [==============================] - 0s 240us/step - loss: 0.3478 - accuracy: 0.8913 - val_loss: 1.4096 - val_accuracy: 0.0323\n",
      "Epoch 178/200\n",
      "46/46 [==============================] - 0s 235us/step - loss: 0.3467 - accuracy: 0.8913 - val_loss: 1.4114 - val_accuracy: 0.0323\n",
      "Epoch 179/200\n",
      "46/46 [==============================] - 0s 186us/step - loss: 0.3458 - accuracy: 0.8913 - val_loss: 1.4148 - val_accuracy: 0.0323\n",
      "Epoch 180/200\n",
      "46/46 [==============================] - 0s 194us/step - loss: 0.3449 - accuracy: 0.8913 - val_loss: 1.4176 - val_accuracy: 0.0323\n",
      "Epoch 181/200\n",
      "46/46 [==============================] - 0s 202us/step - loss: 0.3440 - accuracy: 0.8913 - val_loss: 1.4201 - val_accuracy: 0.0323\n",
      "Epoch 182/200\n",
      "46/46 [==============================] - 0s 166us/step - loss: 0.3429 - accuracy: 0.8913 - val_loss: 1.4223 - val_accuracy: 0.0323\n",
      "Epoch 183/200\n",
      "46/46 [==============================] - 0s 206us/step - loss: 0.3421 - accuracy: 0.8913 - val_loss: 1.4243 - val_accuracy: 0.0323\n",
      "Epoch 184/200\n",
      "46/46 [==============================] - 0s 175us/step - loss: 0.3412 - accuracy: 0.8913 - val_loss: 1.4269 - val_accuracy: 0.0323\n",
      "Epoch 185/200\n",
      "46/46 [==============================] - 0s 196us/step - loss: 0.3403 - accuracy: 0.8913 - val_loss: 1.4304 - val_accuracy: 0.0323\n",
      "Epoch 186/200\n",
      "46/46 [==============================] - 0s 195us/step - loss: 0.3394 - accuracy: 0.8913 - val_loss: 1.4334 - val_accuracy: 0.0323\n",
      "Epoch 187/200\n",
      "46/46 [==============================] - 0s 177us/step - loss: 0.3385 - accuracy: 0.8913 - val_loss: 1.4361 - val_accuracy: 0.0323\n",
      "Epoch 188/200\n",
      "46/46 [==============================] - 0s 199us/step - loss: 0.3375 - accuracy: 0.8913 - val_loss: 1.4389 - val_accuracy: 0.0323\n",
      "Epoch 189/200\n",
      "46/46 [==============================] - 0s 188us/step - loss: 0.3367 - accuracy: 0.8913 - val_loss: 1.4419 - val_accuracy: 0.0323\n",
      "Epoch 190/200\n",
      "46/46 [==============================] - 0s 190us/step - loss: 0.3357 - accuracy: 0.8913 - val_loss: 1.4449 - val_accuracy: 0.0323\n",
      "Epoch 191/200\n",
      "46/46 [==============================] - 0s 191us/step - loss: 0.3350 - accuracy: 0.8913 - val_loss: 1.4468 - val_accuracy: 0.0323\n",
      "Epoch 192/200\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.3342 - accuracy: 0.8913 - val_loss: 1.4503 - val_accuracy: 0.0323\n",
      "Epoch 193/200\n",
      "46/46 [==============================] - 0s 249us/step - loss: 0.3331 - accuracy: 0.8913 - val_loss: 1.4532 - val_accuracy: 0.0323\n",
      "Epoch 194/200\n",
      "46/46 [==============================] - 0s 206us/step - loss: 0.3325 - accuracy: 0.8913 - val_loss: 1.4562 - val_accuracy: 0.0323\n",
      "Epoch 195/200\n",
      "46/46 [==============================] - 0s 257us/step - loss: 0.3314 - accuracy: 0.8913 - val_loss: 1.4571 - val_accuracy: 0.0323\n",
      "Epoch 196/200\n",
      "46/46 [==============================] - 0s 188us/step - loss: 0.3308 - accuracy: 0.8913 - val_loss: 1.4603 - val_accuracy: 0.0323\n",
      "Epoch 197/200\n",
      "46/46 [==============================] - 0s 189us/step - loss: 0.3298 - accuracy: 0.8913 - val_loss: 1.4636 - val_accuracy: 0.0323\n",
      "Epoch 198/200\n",
      "46/46 [==============================] - 0s 203us/step - loss: 0.3291 - accuracy: 0.8913 - val_loss: 1.4663 - val_accuracy: 0.0323\n",
      "Epoch 199/200\n",
      "46/46 [==============================] - 0s 451us/step - loss: 0.3281 - accuracy: 0.8913 - val_loss: 1.4673 - val_accuracy: 0.0323\n",
      "Epoch 200/200\n",
      "46/46 [==============================] - 0s 233us/step - loss: 0.3276 - accuracy: 0.8913 - val_loss: 1.4703 - val_accuracy: 0.0323\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "in_dimension = X_train.shape[1]\n",
    "\n",
    "freq_model = Sequential()\n",
    "freq_model.add(Dense(5, activation='relu', input_dim=in_dimension))\n",
    "#freq_model.add(Dropout(0.5))\n",
    "#freq_model.add(Dense(10, activation='relu'))\n",
    "#freq_model.add(Dropout(0.5))\n",
    "#freq_model.add(Dense(32, activation='relu'))\n",
    "freq_model.add(Dense(1, activation='sigmoid'))\n",
    "freq_model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "#freq_model.fit(X_train, y_train, epochs=200, batch_size=32)\n",
    "\n",
    "history = freq_model.fit(pca_regressor, outputs, validation_split=0.40, epochs=200, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "In this part it is presented the results from the classification algorithm. Both regarding the data visualization and the model classification quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "\n",
    "From this results it is possible to see that the classifier using periodogram amplitudes can get some interesting knowledge on the eclipsing binaries classification, but could not extract any information to classify properly the confirmed targets. It is almost as if the model is blind when an exo planet periodogram is presented as feature to the algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes likelihood\n",
    "\n",
    "Here we will read the Naive Bayes model parameters estimated for each light curve and use this information as feature for the xgBoost classifier. To start this approach, we must first read the Bayes features saved from last step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'labels'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "file_name = './features/bayes_data/nx_6/bayes_data.pkl'\n",
    "with open(file_name, 'rb') as file:\n",
    "    bayes_data = pickle.load(file)\n",
    "bayes_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate features\n",
    "\n",
    "After reading the data, it is necessary to create the classical regression structure model in the format $Y = f\\left(\\Theta, X\\right)$, normalize the feature data and encode any possible label data into numerical classes. This is just the preparation for the machine leaning algorithm to guarantee that the provided info is properlly designed for any machine learning classical form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Create the label encoder\n",
    "le_bayes = preprocessing.LabelEncoder()\n",
    "le_bayes.fit(bayes_data['labels'])\n",
    "\n",
    "# Define the regression model\n",
    "regressors = preprocessing.normalize(bayes_data['features']['params'])\n",
    "outputs = le_bayes.transform(bayes_data['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test data split\n",
    "\n",
    "Next it is necessary to segregate the data into a set for validation and one for trainning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "    regressors, outputs, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper tunning\n",
    "\n",
    "We could consider tunning the model hyper parameters to answer questions such as:\n",
    "\n",
    "- Wich value of `n_estimators` is the best for this model and data?\n",
    "- Wich cost function is the best to be selected as `objective` for this model?\n",
    "\n",
    "We could do a hyper search, to find the best hyper parameters for this model, automating the hyper parameter selection. There are several already builded algorithms to optimize this parameter search, and build find with high performance the best parameters, provided a set of possible values. But, to understand what those algorithms actually does, we could once build our own search algorithm...\n",
    "\n",
    "As an example, lets run a first handly defined hyper parameter tunning using the confusion matrix of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define the model parameters \n",
    "param_dist = {\n",
    "    'objective':'binary:logistic', \n",
    "    'n_estimators' : 11\n",
    "}\n",
    "\n",
    "# Create the range parameters to \n",
    "# search\n",
    "n_estimators = [ k+1 for k in range(100)]\n",
    "\n",
    "# Create the plotting variable\n",
    "plot_vals = {\n",
    "    'true': {\n",
    "        'confirmed targets': [],\n",
    "        'eclipsing binaries': [],\n",
    "    },\n",
    "    'false': {\n",
    "        'confirmed targets': [],\n",
    "        'eclipsing binaries': [],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Estimate and validate each candidate\n",
    "for opt in n_estimators:\n",
    "    # Update the model parameters\n",
    "    param_dist['n_estimators'] = opt\n",
    "    # Create the xgBoost classifier\n",
    "    clfs = xgb.XGBRFClassifier(**param_dist)\n",
    "    # Fit the model to the data\n",
    "    clfs.fit(X_train, y_train,\n",
    "            eval_metric='logloss',\n",
    "            verbose=True)\n",
    "    # Estimate the test output\n",
    "    y_pred = clfs.predict(X_test)\n",
    "    # Compute the confusion matrix\n",
    "    conf_mat = confusion_matrix(\n",
    "        y_test, y_pred,\n",
    "        normalize='true')\n",
    "    # Save the confusion matrix\n",
    "    plot_vals['true']['confirmed targets'].append(conf_mat[0,0])\n",
    "    plot_vals['true']['eclipsing binaries'].append(conf_mat[1,1])\n",
    "    plot_vals['false']['confirmed targets'].append(conf_mat[0,1])\n",
    "    plot_vals['false']['eclipsing binaries'].append(conf_mat[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "# Line plot each confidence matrix parameter\n",
    "x_data = [n_estimators, n_estimators, n_estimators, n_estimators]\n",
    "y_data = [plot_vals['true']['confirmed targets'],\n",
    "          plot_vals['true']['eclipsing binaries'],\n",
    "          plot_vals['false']['confirmed targets'],\n",
    "          plot_vals['false']['eclipsing binaries']]\n",
    "legends= ['True - C.T.', 'True - E.B.', 'False - C.T.', 'False - E.B.']\n",
    "colors = [6, 7, 2, 3]\n",
    "\n",
    "p = visual.multline_plot(x_data, y_data,\n",
    "                         legend_label=legends, \n",
    "                         title='Hyper parameter search - Confusion parameters plot',\n",
    "                         color_index=colors,\n",
    "                         y_axis={'label': 'Proportion'},\n",
    "                         x_axis={'label': 'n_estimators'})\n",
    "visual.show_plot(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "After running the hyper parameter search we can create a model with the best defined hyper parameters, or setup parameters, and consolidate the model in to the best version for further performance analysis. The model is saved on a particular variable, such as `bayes_clf` to be further used in some vote chain model, if further necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46 samples, validate on 31 samples\n",
      "Epoch 1/20\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5435 - val_loss: 0.7137 - val_accuracy: 0.1935\n",
      "Epoch 2/20\n",
      "46/46 [==============================] - 0s 158us/step - loss: 0.6891 - accuracy: 0.7391 - val_loss: 0.7194 - val_accuracy: 0.0323\n",
      "Epoch 3/20\n",
      "46/46 [==============================] - 0s 162us/step - loss: 0.6853 - accuracy: 0.8043 - val_loss: 0.7250 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "46/46 [==============================] - 0s 227us/step - loss: 0.6815 - accuracy: 0.8043 - val_loss: 0.7305 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "46/46 [==============================] - 0s 213us/step - loss: 0.6779 - accuracy: 0.8043 - val_loss: 0.7360 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "46/46 [==============================] - 0s 212us/step - loss: 0.6743 - accuracy: 0.8043 - val_loss: 0.7416 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "46/46 [==============================] - 0s 240us/step - loss: 0.6709 - accuracy: 0.8043 - val_loss: 0.7471 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "46/46 [==============================] - 0s 229us/step - loss: 0.6675 - accuracy: 0.8043 - val_loss: 0.7525 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "46/46 [==============================] - 0s 281us/step - loss: 0.6643 - accuracy: 0.8043 - val_loss: 0.7578 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "46/46 [==============================] - 0s 308us/step - loss: 0.6612 - accuracy: 0.8043 - val_loss: 0.7629 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "46/46 [==============================] - 0s 340us/step - loss: 0.6583 - accuracy: 0.8043 - val_loss: 0.7681 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "46/46 [==============================] - 0s 328us/step - loss: 0.6554 - accuracy: 0.8043 - val_loss: 0.7732 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "46/46 [==============================] - 0s 285us/step - loss: 0.6526 - accuracy: 0.8043 - val_loss: 0.7784 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "46/46 [==============================] - 0s 333us/step - loss: 0.6498 - accuracy: 0.8043 - val_loss: 0.7835 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "46/46 [==============================] - 0s 298us/step - loss: 0.6471 - accuracy: 0.8043 - val_loss: 0.7885 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "46/46 [==============================] - 0s 303us/step - loss: 0.6446 - accuracy: 0.8043 - val_loss: 0.7937 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.6420 - accuracy: 0.8043 - val_loss: 0.7986 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "46/46 [==============================] - 0s 342us/step - loss: 0.6396 - accuracy: 0.8043 - val_loss: 0.8036 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "46/46 [==============================] - 0s 205us/step - loss: 0.6372 - accuracy: 0.8043 - val_loss: 0.8084 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "46/46 [==============================] - 0s 289us/step - loss: 0.6349 - accuracy: 0.8043 - val_loss: 0.8133 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "in_dimension = X_train.shape[1]\n",
    "\n",
    "bayes_model = Sequential()\n",
    "bayes_model.add(Dense(12, activation='relu', input_dim=in_dimension))\n",
    "#bayes_model.add(Dropout(0.5))\n",
    "bayes_model.add(Dense(6, activation='relu'))\n",
    "#bayes_model.add(Dropout(0.5))\n",
    "#bayes_model.add(Dense(32, activation='relu'))\n",
    "bayes_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "opt = optimizers.SGD(lr=0.01, clipvalue=0.9)\n",
    "\n",
    "bayes_model.compile(optimizer=opt,\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "#freq_model.fit(X_train, y_train, epochs=200, batch_size=32)\n",
    "\n",
    "history = bayes_model.fit(regressors, outputs, validation_split=0.40, epochs=20, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "In this part it is presented the results from the classification algorithm. Both regarding the data visualization and the model classification quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "\n",
    "From this results it is possible to see that the classifier using Naive Bayes estimated model parameters is able to highly characterize the eclipsing binaries, and has acceptable classification performance for the confirmed targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hidden Markov Models\n",
    "\n",
    "Here we use the model estimated from the Hidden Markov Models library, wich is the estimated $A$ matrix, or the so called transition probability matrices as feature for the learning classifier. For that we must read the pickle file with the desired features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "file_name = './features/hmm_data/nx_8/hmm_data.pkl'\n",
    "with open(file_name, 'rb') as file:\n",
    "    hmm_data = pickle.load(file)\n",
    "hmm_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate features\n",
    "\n",
    "After reading the data, it is necessary to create the classical regression structure model in the format $Y = f\\left(\\Theta, X\\right)$, normalize the feature data and encode any possible label data into numerical classes. This is just the preparation for the machine leaning algorithm to guarantee that the provided info is properlly designed for any machine learning classical form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Encode the label\n",
    "le_hmm = preprocessing.LabelEncoder()\n",
    "le_hmm.fit( hmm_data['labels'] )\n",
    "\n",
    "# Define the model order\n",
    "feat = hmm_data['features']\n",
    "nx = feat['prob_matrix'][0].shape[0]\n",
    "\n",
    "regressors = []\n",
    "for phi in feat['prob_matrix']:\n",
    "    # Reshape the regressor\n",
    "    reg = phi.reshape(nx*nx)\n",
    "    # Add to the regressors\n",
    "    regressors.append(reg)   \n",
    "# Normalize the regressors\n",
    "regressors = preprocessing.normalize(regressors)\n",
    "# Define outputs as encoded variables\n",
    "outputs = le_hmm.transform(hmm_data['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test data split\n",
    "\n",
    "Next it is necessary to segregate the data into a set for validation and one for trainning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "    regressors, outputs, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper tunning\n",
    "\n",
    "We could consider tunning the model hyper parameters to answer questions such as:\n",
    "\n",
    "- Wich value of `n_estimators` is the best for this model and data?\n",
    "- Wich cost function is the best to be selected as `objective` for this model?\n",
    "\n",
    "We could do a hyper search, to find the best hyper parameters for this model, automating the hyper parameter selection. There are several already builded algorithms to optimize this parameter search, and build find with high performance the best parameters, provided a set of possible values. But, to understand what those algorithms actually does, we could once build our own search algorithm...\n",
    "\n",
    "As an example, lets run a first handly defined hyper parameter tunning using the confusion matrix of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "n_estimators = [ k+1 for k in range(100)]\n",
    "\n",
    "conf_matrices = []\n",
    "for opt in n_estimators:\n",
    "    # Update the model parameters\n",
    "    param_dist['n_estimators'] = opt\n",
    "    # Create the xgBoost classifier\n",
    "    clfs = xgb.XGBRFClassifier(**param_dist)\n",
    "    # Fit the model to the data\n",
    "    clfs.fit(X_train, y_train,\n",
    "            eval_metric='logloss',\n",
    "            verbose=True)\n",
    "    # Estimate the test output\n",
    "    y_pred = clfs.predict(X_test)\n",
    "    # Compute the confusion matrix\n",
    "    conf_mat = confusion_matrix(\n",
    "        y_test, y_pred,\n",
    "        normalize='true')\n",
    "    # Save the confusion matrix\n",
    "    conf_matrices.append(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "# Create and organize the plot values\n",
    "plot_vals = {\n",
    "    'true': {\n",
    "        'confirmed targets': [],\n",
    "        'eclipsing binaries': [],\n",
    "    },\n",
    "    'false': {\n",
    "        'confirmed targets': [],\n",
    "        'eclipsing binaries': [],\n",
    "    }\n",
    "}\n",
    "for result in conf_matrices:\n",
    "    plot_vals['true']['confirmed targets'].append(result[0,0])\n",
    "    plot_vals['true']['eclipsing binaries'].append(result[1,1])\n",
    "    plot_vals['false']['confirmed targets'].append(result[0,1])\n",
    "    plot_vals['false']['eclipsing binaries'].append(result[1,0])\n",
    "\n",
    "x_values = range(len(conf_matrices))\n",
    "x_data = [x_values, x_values, x_values, x_values]\n",
    "y_data = [plot_vals['true']['confirmed targets'],\n",
    "          plot_vals['true']['eclipsing binaries'],\n",
    "          plot_vals['false']['confirmed targets'],\n",
    "          plot_vals['false']['eclipsing binaries']]\n",
    "legends= ['True - C.T.', 'True - E.B.', 'False - C.T.', 'False - E.B.']\n",
    "colors = [6, 7, 2, 3]\n",
    "\n",
    "p = visual.multline_plot(x_data, y_data,\n",
    "                         legend_label=legends, \n",
    "                         title='Hyper parameter search - Confusion plot',\n",
    "                         color_index=colors,\n",
    "                         y_axis={'label': 'Intensity'},\n",
    "                         x_axis={'label': 'n_estimators'})\n",
    "visual.show_plot(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user might see that the best values for the `n_estimators` parameter is something close to `[4,5,6]`. When we have a range of values, such as here, usually is advisable to use the simpler model, in this case `n_estimators=4`, wich is the value defined before.\n",
    "\n",
    "> *Notice that the value `n_estimators`$=n_x$ defined in the previous step algorithm. Since the hidden markov model is pretty simple such as the classifier. Therefore is possible that the hidden markov model is underfitted, this means that the markov model is to simple to represent the information from the ligt curve, since there is no redundancy on the model. This is infered by checking that `n_estimators`$=n_x$ is the best solution for this problem.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "After running the hyper parameter search we can create a model with the best defined hyper parameters, or setup parameters, and consolidate the model in to the best version for further performance analysis. The model is saved on a particular variable, such as `hmm_clf` to be further used in some vote chain model, if further necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "param_dist = {\n",
    "    'verbosity': 0,\n",
    "    'objective':'binary:logistic', \n",
    "    'n_estimators' : 5\n",
    "}\n",
    "\n",
    "hmm_clf = xgb.XGBRFClassifier(**param_dist)\n",
    "\n",
    "hmm_clf.fit(X_train, y_train,\n",
    "            eval_set=[\n",
    "                (X_train, y_train), \n",
    "                (X_test, y_test)\n",
    "            ],\n",
    "            eval_metric='logloss',\n",
    "            verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Here we include some visualization results for the xgBoost algorithm classification. As the first result, we just print the model eval metrics, here the *log loss* of the model, for both the trainning and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "evals_result = hmm_clf.evals_result()\n",
    "pp.pprint(evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "disp = plot_confusion_matrix(hmm_clf, X_test, y_test,\n",
    "                             display_labels=le_hmm.classes_,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize='true')\n",
    "disp.ax_.set_title('Hidden Markov Models - Confusion matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
