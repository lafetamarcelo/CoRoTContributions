

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>XGBoost Classifier &mdash; CoRoT Contributions</title>
  

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Decision trees" href="03 - Machine Learning - Decision Trees.html" />
    <link rel="prev" title="Reading the data" href="02 - Building and creating features.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> CoRoT Contributions
          

          
            
            <img src="_static/corot_logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Reading and Plotting</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="01 - Reading and Plotting.html">Read <em>.fits</em> raw data</a></li>
<li class="toctree-l1"><a class="reference internal" href="01 - Reading and Plotting.html#Preprocessing-data">Preprocessing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="01 - Reading and Plotting.html#Resampling-series">Resampling series</a></li>
<li class="toctree-l1"><a class="reference internal" href="01 - Reading and Plotting.html#Filtering-series">Filtering series</a></li>
<li class="toctree-l1"><a class="reference internal" href="01 - Reading and Plotting.html#Application-example">Application example</a></li>
<li class="toctree-l1"><a class="reference internal" href="01 - Reading and Plotting.html#Generation-algorithms">Generation algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="01 - Reading and Plotting.html#Save-pre-processed-data">Save pre-processed data</a></li>
</ul>
<p class="caption"><span class="caption-text">Feature Engineering</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="02 - Building and creating features.html">Reading the data</a></li>
<li class="toctree-l1"><a class="reference internal" href="02 - Building and creating features.html#Feature:-Frequency-response">Feature: Frequency response</a></li>
<li class="toctree-l1"><a class="reference internal" href="02 - Building and creating features.html#Feature:-Naive-Bayes-likelihood">Feature: Naive Bayes likelihood</a></li>
<li class="toctree-l1"><a class="reference internal" href="02 - Building and creating features.html#Feature:-Markov-Hidden-Models">Feature: Markov Hidden Models</a></li>
</ul>
<p class="caption"><span class="caption-text">Machine Learning</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">XGBoost Classifier</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Periodograms">Periodograms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Manipulate-features">Manipulate features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Train-test-data-split">Train-test data split</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Hyper-tunning">Hyper tunning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Train-model">Train model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Results">Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Comments">Comments</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Naive-Bayes-likelihood">Naive Bayes likelihood</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Manipulate features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">Train-test data split</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">Hyper tunning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">Train model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id6">Comments</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Hidden-Markov-Models">Hidden Markov Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id7">Manipulate features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id8">Train-test data split</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id9">Hyper tunning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">Train model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id11">Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id12">Comments</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="03 - Machine Learning - Decision Trees.html">Decision trees</a></li>
</ul>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modules.html">CoRoTContributions</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">CoRoT Contributions</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>XGBoost Classifier</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/03 - Machine Learning - XGBoost Classifier.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    min-width: 5ex;
    padding-top: 0.3rem;
    padding-right: 0.3rem;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 0.3rem;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="XGBoost-Classifier">
<h1>XGBoost Classifier<a class="headerlink" href="#XGBoost-Classifier" title="Permalink to this headline">¶</a></h1>
<p>The first algorithm that we will use is the XGBoost with its classic classifier. This is the classic simple algorithm from XGBoost library, further a more complex one will be used. This algorithm will be used for each generated feature, namelly:</p>
<ul class="simple">
<li><p>Periodograms</p></li>
<li><p>Bayes Similarity</p></li>
<li><p>Hidden Markov Models</p></li>
</ul>
<p>All approaches will pass trough the common machine learning pipeline, where we must:</p>
<ul class="simple">
<li><p>Normalize the data (if necessary)</p></li>
<li><p>Divide the data between trainning and testing</p></li>
<li><p>Search the hyper parameters</p></li>
<li><p>Cross validate the models</p></li>
<li><p>Analyse the results</p></li>
</ul>
<div class="section" id="Periodograms">
<h2>Periodograms<a class="headerlink" href="#Periodograms" title="Permalink to this headline">¶</a></h2>
<p>The application using the periodograms is actually pretty simple, now that the data is prepared and all of those preprocessing from last pipeline step is already done. The algorithm became straigh forward. First it is necessary to read the features generated.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pickle</span>

<span class="n">file_name</span> <span class="o">=</span> <span class="s1">&#39;./features/freq_data/freq_data.pkl&#39;</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">freq_data</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
<span class="n">freq_data</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
dict_keys([&#39;features&#39;, &#39;labels&#39;])
</pre></div></div>
</div>
<div class="section" id="Manipulate-features">
<h3>Manipulate features<a class="headerlink" href="#Manipulate-features" title="Permalink to this headline">¶</a></h3>
<p>After reading the data, it is necessary to create the classical regression structure model in the format <span class="math notranslate nohighlight">\(Y = f\left(\Theta, X\right)\)</span>, normalize the feature data and encode any possible label data into numerical classes. This is just the preparation for the machine leaning algorithm to guarantee that the provided info is properlly designed for any machine learning classical form.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>

<span class="c1"># Create the label encoder</span>
<span class="n">le_freq</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">le_freq</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">freq_data</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">])</span>

<span class="c1"># Define the regression model</span>
<span class="n">regressors</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">freq_data</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">][</span><span class="s1">&#39;spec&#39;</span><span class="p">])</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">le_freq</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">freq_data</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">regressors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
12758
</pre></div></div>
</div>
<p>Also it is interesting to reduce the features dimension to build a simpler model. It is not necessary to create a classifier with such amount (12758 features…) of features. There are several techniques that can be used to reduce the features dimensions. The Principal Component Analisys, is very effective when dealing with high dimensional data. Here the <code class="docutils literal notranslate"><span class="pre">PCA</span></code> algorithm from the <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> library is used.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="c1"># Create the PCA decomposer</span>
<span class="n">pca_dec</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">70</span><span class="p">,</span> <span class="n">svd_solver</span><span class="o">=</span><span class="s1">&#39;arpack&#39;</span><span class="p">)</span>

<span class="c1"># Train the PCA object</span>
<span class="n">pca_dec</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">regressors</span><span class="p">)</span>

<span class="c1"># Transform the data using</span>
<span class="c1"># the PCA model</span>
<span class="n">pca_regressor</span> <span class="o">=</span> <span class="n">pca_dec</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">regressors</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Train-test-data-split">
<h3>Train-test data split<a class="headerlink" href="#Train-test-data-split" title="Permalink to this headline">¶</a></h3>
<p>Next it is necessary to segregate the data into a set for validation and one for trainning the model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">pca_regressor</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Hyper-tunning">
<h3>Hyper tunning<a class="headerlink" href="#Hyper-tunning" title="Permalink to this headline">¶</a></h3>
<p>We could consider tunning the model hyper parameters to answer questions such as:</p>
<ul class="simple">
<li><p>Wich value of <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> is the best for this model and data?</p></li>
<li><p>Wich cost function is the best to be selected as <code class="docutils literal notranslate"><span class="pre">objective</span></code> for this model?</p></li>
</ul>
<p>We could do a hyper search, to find the best hyper parameters for this model, automating the hyper parameter selection. There are several already builded algorithms to optimize this parameter search, and build find with high performance the best parameters, provided a set of possible values. But, to understand what those algorithms actually does, we could once build our own search algorithm…</p>
<p>As an example, lets run a first handly defined hyper parameter tunning using the confusion matrix of the model:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="c1"># Define the model parameters</span>
<span class="n">param_dist</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;objective&#39;</span><span class="p">:</span><span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span>
    <span class="s1">&#39;n_estimators&#39;</span> <span class="p">:</span> <span class="mi">11</span>
<span class="p">}</span>

<span class="c1"># Create the range parameters to</span>
<span class="c1"># search</span>
<span class="n">n_estimators</span> <span class="o">=</span> <span class="p">[</span> <span class="n">k</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>

<span class="c1"># Create the plotting variable</span>
<span class="n">plot_vals</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;true&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;confirmed targets&#39;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">},</span>
    <span class="s1">&#39;false&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;confirmed targets&#39;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Estimate and validate each candidate</span>
<span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">n_estimators</span><span class="p">:</span>
    <span class="c1"># Update the model parameters</span>
    <span class="n">param_dist</span><span class="p">[</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">opt</span>
    <span class="c1"># Create the xgBoost classifier</span>
    <span class="n">clfs</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">param_dist</span><span class="p">)</span>
    <span class="c1"># Fit the model to the data</span>
    <span class="n">clfs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
            <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;logloss&#39;</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># Estimate the test output</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">clfs</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="c1"># Compute the confusion matrix</span>
    <span class="n">conf_mat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span>
        <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="s1">&#39;true&#39;</span><span class="p">)</span>
    <span class="c1"># Save the confusion matrix</span>
    <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">][</span><span class="s1">&#39;confirmed targets&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">][</span><span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;false&#39;</span><span class="p">][</span><span class="s1">&#39;confirmed targets&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;false&#39;</span><span class="p">][</span><span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Line plot each confidence matrix parameter</span>
<span class="n">x_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">n_estimators</span><span class="p">,</span> <span class="n">n_estimators</span><span class="p">,</span> <span class="n">n_estimators</span><span class="p">]</span>
<span class="n">y_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">][</span><span class="s1">&#39;confirmed targets&#39;</span><span class="p">],</span>
          <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">][</span><span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">],</span>
          <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;false&#39;</span><span class="p">][</span><span class="s1">&#39;confirmed targets&#39;</span><span class="p">],</span>
          <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;false&#39;</span><span class="p">][</span><span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">]]</span>
<span class="n">legends</span><span class="o">=</span> <span class="p">[</span><span class="s1">&#39;True - C.T.&#39;</span><span class="p">,</span> <span class="s1">&#39;True - E.B.&#39;</span><span class="p">,</span> <span class="s1">&#39;False - C.T.&#39;</span><span class="p">,</span> <span class="s1">&#39;False - E.B.&#39;</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">visual</span><span class="o">.</span><span class="n">multline_plot</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span>
                         <span class="n">legend_label</span><span class="o">=</span><span class="n">legends</span><span class="p">,</span>
                         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Hyper parameter search - Confusion parameters plot&#39;</span><span class="p">,</span>
                         <span class="n">color_index</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span>
                         <span class="n">y_axis</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Proportion&#39;</span><span class="p">},</span>
                         <span class="n">x_axis</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">})</span>
<span class="n">visual</span><span class="o">.</span><span class="n">show_plot</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<div class="bk-root">
    <a href="https://bokeh.org" target="_blank" class="bk-logo bk-logo-small bk-logo-notebook"></a>
    <span id="1001">Loading BokehJS ...</span>
</div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="output_javascript"></div>
<script type="text/javascript">
var element = document.currentScript.previousSibling.previousSibling;

(function(root) {
  function now() {
    return new Date();
  }

  var force = true;

  if (typeof root._bokeh_onload_callbacks === "undefined" || force === true) {
    root._bokeh_onload_callbacks = [];
    root._bokeh_is_loading = undefined;
  }

  var JS_MIME_TYPE = 'application/javascript';
  var HTML_MIME_TYPE = 'text/html';
  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';
  var CLASS_NAME = 'output_bokeh rendered_html';

  /**
   * Render data to the DOM node
   */
  function render(props, node) {
    var script = document.createElement("script");
    node.appendChild(script);
  }

  /**
   * Handle when an output is cleared or removed
   */
  function handleClearOutput(event, handle) {
    var cell = handle.cell;

    var id = cell.output_area._bokeh_element_id;
    var server_id = cell.output_area._bokeh_server_id;
    // Clean up Bokeh references
    if (id != null && id in Bokeh.index) {
      Bokeh.index[id].model.document.clear();
      delete Bokeh.index[id];
    }

    if (server_id !== undefined) {
      // Clean up Bokeh references
      var cmd = "from bokeh.io.state import curstate; print(curstate().uuid_to_server['" + server_id + "'].get_sessions()[0].document.roots[0]._id)";
      cell.notebook.kernel.execute(cmd, {
        iopub: {
          output: function(msg) {
            var id = msg.content.text.trim();
            if (id in Bokeh.index) {
              Bokeh.index[id].model.document.clear();
              delete Bokeh.index[id];
            }
          }
        }
      });
      // Destroy server and session
      var cmd = "import bokeh.io.notebook as ion; ion.destroy_server('" + server_id + "')";
      cell.notebook.kernel.execute(cmd);
    }
  }

  /**
   * Handle when a new output is added
   */
  function handleAddOutput(event, handle) {
    var output_area = handle.output_area;
    var output = handle.output;

    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only
    if ((output.output_type != "display_data") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {
      return
    }

    var toinsert = output_area.element.find("." + CLASS_NAME.split(' ')[0]);

    if (output.metadata[EXEC_MIME_TYPE]["id"] !== undefined) {
      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];
      // store reference to embed id on output_area
      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE]["id"];
    }
    if (output.metadata[EXEC_MIME_TYPE]["server_id"] !== undefined) {
      var bk_div = document.createElement("div");
      bk_div.innerHTML = output.data[HTML_MIME_TYPE];
      var script_attrs = bk_div.children[0].attributes;
      for (var i = 0; i < script_attrs.length; i++) {
        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);
        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent
      }
      // store reference to server id on output_area
      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE]["server_id"];
    }
  }

  function register_renderer(events, OutputArea) {

    function append_mime(data, metadata, element) {
      // create a DOM node to render to
      var toinsert = this.create_output_subarea(
        metadata,
        CLASS_NAME,
        EXEC_MIME_TYPE
      );
      this.keyboard_manager.register_events(toinsert);
      // Render to node
      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};
      render(props, toinsert[toinsert.length - 1]);
      element.append(toinsert);
      return toinsert
    }

    /* Handle when an output is cleared or removed */
    events.on('clear_output.CodeCell', handleClearOutput);
    events.on('delete.Cell', handleClearOutput);

    /* Handle when a new output is added */
    events.on('output_added.OutputArea', handleAddOutput);

    /**
     * Register the mime type and append_mime function with output_area
     */
    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {
      /* Is output safe? */
      safe: true,
      /* Index of renderer in `output_area.display_order` */
      index: 0
    });
  }

  // register the mime type if in Jupyter Notebook environment and previously unregistered
  if (root.Jupyter !== undefined) {
    var events = require('base/js/events');
    var OutputArea = require('notebook/js/outputarea').OutputArea;

    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {
      register_renderer(events, OutputArea);
    }
  }


  if (typeof (root._bokeh_timeout) === "undefined" || force === true) {
    root._bokeh_timeout = Date.now() + 5000;
    root._bokeh_failed_load = false;
  }

  var NB_LOAD_WARNING = {'data': {'text/html':
     "<div style='background-color: #fdd'>\n"+
     "<p>\n"+
     "BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \n"+
     "may be due to a slow or bad network connection. Possible fixes:\n"+
     "</p>\n"+
     "<ul>\n"+
     "<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\n"+
     "<li>use INLINE resources instead, as so:</li>\n"+
     "</ul>\n"+
     "<code>\n"+
     "from bokeh.resources import INLINE\n"+
     "output_notebook(resources=INLINE)\n"+
     "</code>\n"+
     "</div>"}};

  function display_loaded() {
    var el = document.getElementById("1001");
    if (el != null) {
      el.textContent = "BokehJS is loading...";
    }
    if (root.Bokeh !== undefined) {
      if (el != null) {
        el.textContent = "BokehJS " + root.Bokeh.version + " successfully loaded.";
      }
    } else if (Date.now() < root._bokeh_timeout) {
      setTimeout(display_loaded, 100)
    }
  }


  function run_callbacks() {
    try {
      root._bokeh_onload_callbacks.forEach(function(callback) {
        if (callback != null)
          callback();
      });
    } finally {
      delete root._bokeh_onload_callbacks
    }
    console.debug("Bokeh: all callbacks have finished");
  }

  function load_libs(css_urls, js_urls, callback) {
    if (css_urls == null) css_urls = [];
    if (js_urls == null) js_urls = [];

    root._bokeh_onload_callbacks.push(callback);
    if (root._bokeh_is_loading > 0) {
      console.debug("Bokeh: BokehJS is being loaded, scheduling callback at", now());
      return null;
    }
    if (js_urls == null || js_urls.length === 0) {
      run_callbacks();
      return null;
    }
    console.debug("Bokeh: BokehJS not loaded, scheduling load and callback at", now());
    root._bokeh_is_loading = css_urls.length + js_urls.length;

    function on_load() {
      root._bokeh_is_loading--;
      if (root._bokeh_is_loading === 0) {
        console.debug("Bokeh: all BokehJS libraries/stylesheets loaded");
        run_callbacks()
      }
    }

    function on_error() {
      console.error("failed to load " + url);
    }

    for (var i = 0; i < css_urls.length; i++) {
      var url = css_urls[i];
      const element = document.createElement("link");
      element.onload = on_load;
      element.onerror = on_error;
      element.rel = "stylesheet";
      element.type = "text/css";
      element.href = url;
      console.debug("Bokeh: injecting link tag for BokehJS stylesheet: ", url);
      document.body.appendChild(element);
    }

    const hashes = {"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js": "JpP8FXbgAZLkfur7LiK3j9AGBhHNIvF742meBJrjO2ShJDhCG2I1uVvW+0DUtrmc", "https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js": "xZlADit0Q04ISQEdKg2k3L4W9AwQBAuDs9nJL9fM/WwzL1tEU9VPNezOFX0nLEAz", "https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js": "4BuPRZkdMKSnj3zoxiNrQ86XgNw0rYmBOxe7nshquXwwcauupgBF2DHLVG1WuZlV", "https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js": "Dv1SQ87hmDqK6S5OhBf0bCuwAEvL5QYL0PuR/F1SPVhCS/r/abjkbpKDYL2zeM19"};

    for (var i = 0; i < js_urls.length; i++) {
      var url = js_urls[i];
      var element = document.createElement('script');
      element.onload = on_load;
      element.onerror = on_error;
      element.async = false;
      element.src = url;
      if (url in hashes) {
        element.crossOrigin = "anonymous";
        element.integrity = "sha384-" + hashes[url];
      }
      console.debug("Bokeh: injecting script tag for BokehJS library: ", url);
      document.head.appendChild(element);
    }
  };var element = document.getElementById("1001");
  if (element == null) {
    console.error("Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. ")
    return false;
  }

  function inject_raw_css(css) {
    const element = document.createElement("style");
    element.appendChild(document.createTextNode(css));
    document.body.appendChild(element);
  }


  var js_urls = ["https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js"];
  var css_urls = [];


  var inline_js = [
    function(Bokeh) {
      Bokeh.set_log_level("info");
    },
    function(Bokeh) {


    }
  ];

  function run_inline_js() {

    if (root.Bokeh !== undefined || force === true) {

    for (var i = 0; i < inline_js.length; i++) {
      inline_js[i].call(root, root.Bokeh);
    }
    if (force === true) {
        display_loaded();
      }} else if (Date.now() < root._bokeh_timeout) {
      setTimeout(run_inline_js, 100);
    } else if (!root._bokeh_failed_load) {
      console.log("Bokeh: BokehJS failed to load within specified timeout.");
      root._bokeh_failed_load = true;
    } else if (force !== true) {
      var cell = $(document.getElementById("1001")).parents('.cell').data().cell;
      cell.output_area.append_execute_result(NB_LOAD_WARNING)
    }

  }

  if (root._bokeh_is_loading === 0) {
    console.debug("Bokeh: BokehJS loaded, going straight to plotting");
    run_inline_js();
  } else {
    load_libs(css_urls, js_urls, function() {
      console.debug("Bokeh: BokehJS plotting callback run at", now());
      run_inline_js();
    });
  }
}(window));
</script></div>
</div>
<p><img alt="Hyper parameter search - XGBoost Classifier - Periodogram" src="_images/bokeh_plot(23).png" /></p>
</div>
<div class="section" id="Train-model">
<h3>Train model<a class="headerlink" href="#Train-model" title="Permalink to this headline">¶</a></h3>
<p>After running the hyper parameter search we can create a model with the best defined hyper parameters, or setup parameters, and consolidate the model in to the best version for further performance analysis. The model is saved on a particular variable, such as <code class="docutils literal notranslate"><span class="pre">freq_clf</span></code> to be further used in some vote chain model, if further necessary.</p>
<blockquote>
<div><p><em>One interesting result from the above result, is that the best compromise result happens at the :math:`n_x = 5` not on :math:`n_x=4` as it seems. Even though for the :math:`n_x=4` the algorithm is able to get all the exo planets, the compromise on having a confidence of only 66% for the eclipsing binaries classification (classifier close to a coin flipper to classify eclipsing binaries), doesn’t allow us to select :math:`n_x=4`. Therefore the best trade-off on both classes happens at
:math:`n_x=5`.</em></p>
</div></blockquote>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># XGBoost Classifier model parameters</span>
<span class="n">param_dist</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;verbosity&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">&#39;objective&#39;</span><span class="p">:</span><span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span>
    <span class="s1">&#39;n_estimators&#39;</span> <span class="p">:</span> <span class="mi">5</span>
<span class="p">}</span>

<span class="c1"># Create the model classifier</span>
<span class="n">freq_clf</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">param_dist</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">freq_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
              <span class="n">eval_set</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span>
                <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
              <span class="p">],</span>
              <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;logloss&#39;</span><span class="p">,</span>
              <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,
              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,
              importance_type=&#39;gain&#39;, interaction_constraints=None,
              learning_rate=0.300000012, max_delta_step=0, max_depth=6,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              n_estimators=5, n_jobs=0, num_parallel_tree=1,
              objective=&#39;binary:logistic&#39;, random_state=0, reg_alpha=0,
              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,
              validate_parameters=False, verbosity=0)
</pre></div></div>
</div>
</div>
<div class="section" id="Results">
<h3>Results<a class="headerlink" href="#Results" title="Permalink to this headline">¶</a></h3>
<p>In this part it is presented the results from the classification algorithm. Both regarding the data visualization and the model classification quality.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pprint</span>
<span class="n">pp</span> <span class="o">=</span> <span class="n">pprint</span><span class="o">.</span><span class="n">PrettyPrinter</span><span class="p">(</span><span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">pp</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">freq_clf</span><span class="o">.</span><span class="n">evals_result</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{ &#39;validation_0&#39;: { &#39;logloss&#39;: [ 0.537111,
                                 0.449156,
                                 0.384568,
                                 0.327504,
                                 0.280901]},
  &#39;validation_1&#39;: { &#39;logloss&#39;: [ 0.609796,
                                 0.574501,
                                 0.546393,
                                 0.504637,
                                 0.509942]}}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">plot_confusion_matrix</span>

<span class="n">disp</span> <span class="o">=</span> <span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">freq_clf</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span>
                             <span class="n">display_labels</span><span class="o">=</span><span class="n">le_freq</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
                             <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">,</span>
                             <span class="n">normalize</span><span class="o">=</span><span class="s1">&#39;true&#39;</span><span class="p">)</span>
<span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Periodogram Classifier - Confusion matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/03_-_Machine_Learning_-_XGBoost_Classifier_18_0.png" src="_images/03_-_Machine_Learning_-_XGBoost_Classifier_18_0.png" />
</div>
</div>
<div class="section" id="Comments">
<h4>Comments<a class="headerlink" href="#Comments" title="Permalink to this headline">¶</a></h4>
<p><em>From this results it is possible to see that the classifier using periodogram amplitudes can get some interesting knowledge on the eclipsing binaries classification, and have an even better results for the exo planets (confirmed target labels). Also the results are not just good considering the classification capability, but also considering the robustness of the algorithm. The robustness quality can be checked from the printed loss, which shows a continous descending loss for both the test and
train data.</em></p>
</div>
</div>
</div>
<div class="section" id="Naive-Bayes-likelihood">
<h2>Naive Bayes likelihood<a class="headerlink" href="#Naive-Bayes-likelihood" title="Permalink to this headline">¶</a></h2>
<p>Here we will read the Naive Bayes model parameters estimated for each light curve and use this information as feature for the xgBoost classifier. To start this approach, we must first read the Bayes features saved from last step:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pickle</span>

<span class="n">file_name</span> <span class="o">=</span> <span class="s1">&#39;./features/bayes_data/nx_6/bayes_data.pkl&#39;</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">bayes_data</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
<span class="n">bayes_data</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
dict_keys([&#39;features&#39;, &#39;labels&#39;])
</pre></div></div>
</div>
<div class="section" id="id1">
<h3>Manipulate features<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>After reading the data, it is necessary to create the classical regression structure model in the format <span class="math notranslate nohighlight">\(Y = f\left(\Theta, X\right)\)</span>, normalize the feature data and encode any possible label data into numerical classes. This is just the preparation for the machine leaning algorithm to guarantee that the provided info is properlly designed for any machine learning classical form.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>

<span class="c1"># Create the label encoder</span>
<span class="n">le_bayes</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">le_bayes</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">bayes_data</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">])</span>

<span class="c1"># Define the regression model</span>
<span class="n">regressors</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">bayes_data</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">][</span><span class="s1">&#39;params&#39;</span><span class="p">])</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">le_bayes</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">bayes_data</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id2">
<h3>Train-test data split<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>Next it is necessary to segregate the data into a set for validation and one for trainning the model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">regressors</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id3">
<h3>Hyper tunning<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>We could consider tunning the model hyper parameters to answer questions such as:</p>
<ul class="simple">
<li><p>Wich value of <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> is the best for this model and data?</p></li>
<li><p>Wich cost function is the best to be selected as <code class="docutils literal notranslate"><span class="pre">objective</span></code> for this model?</p></li>
</ul>
<p>We could do a hyper search, to find the best hyper parameters for this model, automating the hyper parameter selection. There are several already builded algorithms to optimize this parameter search, and build find with high performance the best parameters, provided a set of possible values. But, to understand what those algorithms actually does, we could once build our own search algorithm…</p>
<p>As an example, lets run a first handly defined hyper parameter tunning using the confusion matrix of the model:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="c1"># Define the model parameters</span>
<span class="n">param_dist</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;objective&#39;</span><span class="p">:</span><span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span>
    <span class="s1">&#39;n_estimators&#39;</span> <span class="p">:</span> <span class="mi">11</span>
<span class="p">}</span>

<span class="c1"># Create the range parameters to</span>
<span class="c1"># search</span>
<span class="n">n_estimators</span> <span class="o">=</span> <span class="p">[</span> <span class="n">k</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>

<span class="c1"># Create the plotting variable</span>
<span class="n">plot_vals</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;true&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;confirmed targets&#39;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">},</span>
    <span class="s1">&#39;false&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;confirmed targets&#39;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Estimate and validate each candidate</span>
<span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">n_estimators</span><span class="p">:</span>
    <span class="c1"># Update the model parameters</span>
    <span class="n">param_dist</span><span class="p">[</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">opt</span>
    <span class="c1"># Create the xgBoost classifier</span>
    <span class="n">clfs</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">param_dist</span><span class="p">)</span>
    <span class="c1"># Fit the model to the data</span>
    <span class="n">clfs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
            <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;logloss&#39;</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># Estimate the test output</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">clfs</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="c1"># Compute the confusion matrix</span>
    <span class="n">conf_mat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span>
        <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="s1">&#39;true&#39;</span><span class="p">)</span>
    <span class="c1"># Save the confusion matrix</span>
    <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">][</span><span class="s1">&#39;confirmed targets&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">][</span><span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;false&#39;</span><span class="p">][</span><span class="s1">&#39;confirmed targets&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;false&#39;</span><span class="p">][</span><span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Line plot each confidence matrix parameter</span>
<span class="n">x_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">n_estimators</span><span class="p">,</span> <span class="n">n_estimators</span><span class="p">,</span> <span class="n">n_estimators</span><span class="p">]</span>
<span class="n">y_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">][</span><span class="s1">&#39;confirmed targets&#39;</span><span class="p">],</span>
          <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">][</span><span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">],</span>
          <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;false&#39;</span><span class="p">][</span><span class="s1">&#39;confirmed targets&#39;</span><span class="p">],</span>
          <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;false&#39;</span><span class="p">][</span><span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">]]</span>
<span class="n">legends</span><span class="o">=</span> <span class="p">[</span><span class="s1">&#39;True - C.T.&#39;</span><span class="p">,</span> <span class="s1">&#39;True - E.B.&#39;</span><span class="p">,</span> <span class="s1">&#39;False - C.T.&#39;</span><span class="p">,</span> <span class="s1">&#39;False - E.B.&#39;</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">visual</span><span class="o">.</span><span class="n">multline_plot</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span>
                         <span class="n">legend_label</span><span class="o">=</span><span class="n">legends</span><span class="p">,</span>
                         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Hyper parameter search - Confusion parameters plot&#39;</span><span class="p">,</span>
                         <span class="n">color_index</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span>
                         <span class="n">y_axis</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Proportion&#39;</span><span class="p">},</span>
                         <span class="n">x_axis</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">})</span>
<span class="n">visual</span><span class="o">.</span><span class="n">show_plot</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p><img alt="Hyper parameter search - XGBoost Classifier - Naive Bayes" src="_images/bokeh_plot(24).png" /></p>
</div>
<div class="section" id="id4">
<h3>Train model<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>After running the hyper parameter search we can create a model with the best defined hyper parameters, or setup parameters, and consolidate the model in to the best version for further performance analysis. The model is saved on a particular variable, such as <code class="docutils literal notranslate"><span class="pre">bayes_clf</span></code> to be further used in some vote chain model, if further necessary.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># XGBoost Classifier model parameters</span>
<span class="n">param_dist</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;verbosity&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">&#39;objective&#39;</span><span class="p">:</span><span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span>
    <span class="s1">&#39;n_estimators&#39;</span> <span class="p">:</span> <span class="mi">11</span>
<span class="p">}</span>

<span class="c1"># Create the model classifier</span>
<span class="n">bayes_clf</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">param_dist</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">bayes_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
              <span class="n">eval_set</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span>
                <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
              <span class="p">],</span>
              <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;logloss&#39;</span><span class="p">,</span>
              <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,
              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,
              importance_type=&#39;gain&#39;, interaction_constraints=None,
              learning_rate=0.300000012, max_delta_step=0, max_depth=6,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              n_estimators=11, n_jobs=0, num_parallel_tree=1,
              objective=&#39;binary:logistic&#39;, random_state=0, reg_alpha=0,
              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,
              validate_parameters=False, verbosity=0)
</pre></div></div>
</div>
</div>
<div class="section" id="id5">
<h3>Results<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>In this part it is presented the results from the classification algorithm. Both regarding the data visualization and the model classification quality.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pprint</span>
<span class="n">pp</span> <span class="o">=</span> <span class="n">pprint</span><span class="o">.</span><span class="n">PrettyPrinter</span><span class="p">(</span><span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">pp</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">bayes_clf</span><span class="o">.</span><span class="n">evals_result</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{ &#39;validation_0&#39;: { &#39;logloss&#39;: [ 0.567346,
                                 0.456689,
                                 0.383979,
                                 0.341458,
                                 0.312702,
                                 0.277829,
                                 0.251812,
                                 0.232627,
                                 0.216223,
                                 0.202809,
                                 0.194951]},
  &#39;validation_1&#39;: { &#39;logloss&#39;: [ 0.657235,
                                 0.599724,
                                 0.567681,
                                 0.561523,
                                 0.556633,
                                 0.547125,
                                 0.553211,
                                 0.528883,
                                 0.531398,
                                 0.528597,
                                 0.536761]}}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">plot_confusion_matrix</span>

<span class="n">disp</span> <span class="o">=</span> <span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">bayes_clf</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span>
                             <span class="n">display_labels</span><span class="o">=</span><span class="n">le_bayes</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
                             <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">,</span>
                             <span class="n">normalize</span><span class="o">=</span><span class="s1">&#39;true&#39;</span><span class="p">)</span>
<span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Bayes Classifier - Confusion matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/03_-_Machine_Learning_-_XGBoost_Classifier_34_0.png" src="_images/03_-_Machine_Learning_-_XGBoost_Classifier_34_0.png" />
</div>
</div>
<div class="section" id="id6">
<h4>Comments<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h4>
<p><em>From this results it is possible to see that the classifier using Naive Bayes estimated model parameters is able to highly characterize the eclipsing binaries, and has acceptable classification performance for the confirmed targets. Also, the algorithm, as in the approach using the Periodograms, is highly consistent, due to the continuous descending loss during learning process for both the trainning and testing data. But comparing with the Periodogram approach, we can ensure that this one is
much more simpler, considering the data preprocessing, than the one using the Periodograms. To generate the periodograms, several artesanal filtering techniques are necessary to generate the data in a suitable format for the machine learning model. Even considering that the classification performance is better then the Naive Bayes, more tests will be necessary to check if this better performace worth the trouble and stability risk of the preprocessing techniques.</em></p>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Hidden-Markov-Models">
<h2>Hidden Markov Models<a class="headerlink" href="#Hidden-Markov-Models" title="Permalink to this headline">¶</a></h2>
<p>Here we use the model estimated from the Hidden Markov Models library, wich is the estimated <span class="math notranslate nohighlight">\(A\)</span> matrix, or the so called transition probability matrices as feature for the learning classifier. For that we must read the pickle file with the desired features:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pickle</span>

<span class="n">file_name</span> <span class="o">=</span> <span class="s1">&#39;./features/hmm_data/nx_8/hmm_data.pkl&#39;</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">hmm_data</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
<span class="n">hmm_data</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
dict_keys([&#39;y&#39;, &#39;t&#39;, &#39;labels&#39;, &#39;features&#39;])
</pre></div></div>
</div>
<div class="section" id="id7">
<h3>Manipulate features<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>After reading the data, it is necessary to create the classical regression structure model in the format <span class="math notranslate nohighlight">\(Y = f\left(\Theta, X\right)\)</span>, normalize the feature data and encode any possible label data into numerical classes. This is just the preparation for the machine leaning algorithm to guarantee that the provided info is properlly designed for any machine learning classical form.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>

<span class="c1"># Encode the label</span>
<span class="n">le_hmm</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">le_hmm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">hmm_data</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="p">)</span>

<span class="c1"># Define the model order</span>
<span class="n">feat</span> <span class="o">=</span> <span class="n">hmm_data</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]</span>
<span class="n">nx</span> <span class="o">=</span> <span class="n">feat</span><span class="p">[</span><span class="s1">&#39;prob_matrix&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">regressors</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">phi</span> <span class="ow">in</span> <span class="n">feat</span><span class="p">[</span><span class="s1">&#39;prob_matrix&#39;</span><span class="p">]:</span>
    <span class="c1"># Reshape the regressor</span>
    <span class="n">reg</span> <span class="o">=</span> <span class="n">phi</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">nx</span><span class="o">*</span><span class="n">nx</span><span class="p">)</span>
    <span class="c1"># Add to the regressors</span>
    <span class="n">regressors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span>
<span class="c1"># Normalize the regressors</span>
<span class="n">regressors</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">regressors</span><span class="p">)</span>
<span class="c1"># Define outputs as encoded variables</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">le_hmm</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">hmm_data</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id8">
<h3>Train-test data split<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>Next it is necessary to segregate the data into a set for validation and one for trainning the model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">regressors</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id9">
<h3>Hyper tunning<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>We could consider tunning the model hyper parameters to answer questions such as:</p>
<ul class="simple">
<li><p>Wich value of <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> is the best for this model and data?</p></li>
<li><p>Wich cost function is the best to be selected as <code class="docutils literal notranslate"><span class="pre">objective</span></code> for this model?</p></li>
</ul>
<p>We could do a hyper search, to find the best hyper parameters for this model, automating the hyper parameter selection. There are several already builded algorithms to optimize this parameter search, and build find with high performance the best parameters, provided a set of possible values. But, to understand what those algorithms actually does, we could once build our own search algorithm…</p>
<p>As an example, lets run a first handly defined hyper parameter tunning using the confusion matrix of the model:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">n_estimators</span> <span class="o">=</span> <span class="p">[</span> <span class="n">k</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>

<span class="n">conf_matrices</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">n_estimators</span><span class="p">:</span>
    <span class="c1"># Update the model parameters</span>
    <span class="n">param_dist</span><span class="p">[</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">opt</span>
    <span class="c1"># Create the xgBoost classifier</span>
    <span class="n">clfs</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">param_dist</span><span class="p">)</span>
    <span class="c1"># Fit the model to the data</span>
    <span class="n">clfs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
            <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;logloss&#39;</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># Estimate the test output</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">clfs</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="c1"># Compute the confusion matrix</span>
    <span class="n">conf_mat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span>
        <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="s1">&#39;true&#39;</span><span class="p">)</span>
    <span class="c1"># Save the confusion matrix</span>
    <span class="n">conf_matrices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create and organize the plot values</span>
<span class="n">plot_vals</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;true&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;confirmed targets&#39;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">},</span>
    <span class="s1">&#39;false&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;confirmed targets&#39;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">}</span>
<span class="p">}</span>
<span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">conf_matrices</span><span class="p">:</span>
    <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">][</span><span class="s1">&#39;confirmed targets&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">][</span><span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;false&#39;</span><span class="p">][</span><span class="s1">&#39;confirmed targets&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;false&#39;</span><span class="p">][</span><span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>

<span class="n">x_values</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">conf_matrices</span><span class="p">))</span>
<span class="n">x_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_values</span><span class="p">,</span> <span class="n">x_values</span><span class="p">,</span> <span class="n">x_values</span><span class="p">,</span> <span class="n">x_values</span><span class="p">]</span>
<span class="n">y_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">][</span><span class="s1">&#39;confirmed targets&#39;</span><span class="p">],</span>
          <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">][</span><span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">],</span>
          <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;false&#39;</span><span class="p">][</span><span class="s1">&#39;confirmed targets&#39;</span><span class="p">],</span>
          <span class="n">plot_vals</span><span class="p">[</span><span class="s1">&#39;false&#39;</span><span class="p">][</span><span class="s1">&#39;eclipsing binaries&#39;</span><span class="p">]]</span>
<span class="n">legends</span><span class="o">=</span> <span class="p">[</span><span class="s1">&#39;True - C.T.&#39;</span><span class="p">,</span> <span class="s1">&#39;True - E.B.&#39;</span><span class="p">,</span> <span class="s1">&#39;False - C.T.&#39;</span><span class="p">,</span> <span class="s1">&#39;False - E.B.&#39;</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">visual</span><span class="o">.</span><span class="n">multline_plot</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span>
                         <span class="n">legend_label</span><span class="o">=</span><span class="n">legends</span><span class="p">,</span>
                         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Hyper parameter search - Confusion plot&#39;</span><span class="p">,</span>
                         <span class="n">color_index</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span>
                         <span class="n">y_axis</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Intensity&#39;</span><span class="p">},</span>
                         <span class="n">x_axis</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">})</span>
<span class="n">visual</span><span class="o">.</span><span class="n">show_plot</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p><img alt="Hyper parameter search - XGBoost Classifier - Hidden Markov Models" src="_images/bokeh_plot(25).png" /></p>
</div>
<div class="section" id="id10">
<h3>Train model<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>After running the hyper parameter search we can create a model with the best defined hyper parameters, or setup parameters, and consolidate the model in to the best version for further performance analysis. The model is saved on a particular variable, such as <code class="docutils literal notranslate"><span class="pre">hmm_clf</span></code> to be further used in some vote chain model, if further necessary.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>

<span class="n">param_dist</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;verbosity&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">&#39;objective&#39;</span><span class="p">:</span><span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span>
    <span class="s1">&#39;n_estimators&#39;</span> <span class="p">:</span> <span class="mi">34</span>
<span class="p">}</span>

<span class="n">hmm_clf</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">param_dist</span><span class="p">)</span>

<span class="n">hmm_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
            <span class="n">eval_set</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span>
                <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
            <span class="p">],</span>
            <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;logloss&#39;</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,
              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,
              importance_type=&#39;gain&#39;, interaction_constraints=None,
              learning_rate=0.300000012, max_delta_step=0, max_depth=6,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              n_estimators=34, n_jobs=0, num_parallel_tree=1,
              objective=&#39;binary:logistic&#39;, random_state=0, reg_alpha=0,
              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,
              validate_parameters=False, verbosity=0)
</pre></div></div>
</div>
</div>
<div class="section" id="id11">
<h3>Results<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<p>Here we include some visualization results for the xgBoost algorithm classification. As the first result, we just print the model eval metrics, here the <em>log loss</em> of the model, for both the trainning and testing data.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pprint</span>
<span class="n">pp</span> <span class="o">=</span> <span class="n">pprint</span><span class="o">.</span><span class="n">PrettyPrinter</span><span class="p">(</span><span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">evals_result</span> <span class="o">=</span> <span class="n">hmm_clf</span><span class="o">.</span><span class="n">evals_result</span><span class="p">()</span>
<span class="n">pp</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">evals_result</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{ &#39;validation_0&#39;: { &#39;logloss&#39;: [ 0.572305,
                                 0.474664,
                                 0.396965,
                                 0.336296,
                                 0.304903,
                                 0.262527,
                                 0.235207,
                                 0.212948,
                                 0.192356,
                                 0.177346,
                                 0.163549,
                                 0.15337,
                                 0.140518,
                                 0.130899,
                                 0.123485,
                                 0.117721,
                                 0.113933,
                                 0.11041,
                                 0.106786,
                                 0.101635,
                                 0.098872,
                                 0.096439,
                                 0.093749,
                                 0.091741,
                                 0.089836,
                                 0.088826,
                                 0.087047,
                                 0.086091,
                                 0.083466,
                                 0.081756,
                                 0.079948,
                                 0.079189,
                                 0.077326,
                                 0.076633]},
  &#39;validation_1&#39;: { &#39;logloss&#39;: [ 0.673667,
                                 0.635211,
                                 0.618026,
                                 0.607399,
                                 0.628232,
                                 0.650925,
                                 0.654683,
                                 0.651218,
                                 0.653813,
                                 0.663263,
                                 0.660528,
                                 0.677213,
                                 0.667749,
                                 0.663841,
                                 0.676913,
                                 0.67355,
                                 0.675848,
                                 0.674091,
                                 0.687084,
                                 0.693771,
                                 0.69817,
                                 0.700085,
                                 0.69875,
                                 0.69817,
                                 0.688993,
                                 0.692456,
                                 0.697232,
                                 0.699571,
                                 0.694171,
                                 0.6861,
                                 0.6878,
                                 0.690059,
                                 0.682183,
                                 0.685172]}}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">plot_confusion_matrix</span>

<span class="n">disp</span> <span class="o">=</span> <span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">hmm_clf</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span>
                             <span class="n">display_labels</span><span class="o">=</span><span class="n">le_hmm</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
                             <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">,</span>
                             <span class="n">normalize</span><span class="o">=</span><span class="s1">&#39;true&#39;</span><span class="p">)</span>
<span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Confusion matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/03_-_Machine_Learning_-_XGBoost_Classifier_50_0.png" src="_images/03_-_Machine_Learning_-_XGBoost_Classifier_50_0.png" />
</div>
</div>
<div class="section" id="id12">
<h4>Comments<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h4>
<p><em>This approch is far the worst one from the ones presented here. This is because, not only the preprocessing algorithms are to heavy and has several stability issues, the algorithm does not have a consistent and desired learning behavior for the test data, when considering the loss. Even though, the algorithm has a consistent classification performance on both classes, this other issues make these results also unstable, therefore it cannot be trusted.</em></p>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="03 - Machine Learning - Decision Trees.html" class="btn btn-neutral float-right" title="Decision trees" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="02 - Building and creating features.html" class="btn btn-neutral float-left" title="Reading the data" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Marcelo Mendes Lafetá Lima

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>